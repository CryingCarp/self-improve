{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hotpot_qa"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:57:59.862084Z",
     "start_time": "2024-09-05T12:57:58.826030Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name:str = \"ambig_qa\"\n",
    "dataset = load_dataset(\"json\", data_files=\"/Users/ariete/Projects/self-improve/output/inference/ambig_qa/react_1000_temperature_0_top-p_1.jsonl\", split=\"train\")\n",
    "if dataset_name == \"trivia_qa\":\n",
    "    dataset = dataset.map(lambda x: {\"answer\": x[\"answer\"][\"normalized_aliases\"]})\n",
    "print(dataset, dataset[0][\"answer\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b35b9ac43ea84427bad4f173abd324f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'answer', 'prediction'],\n",
      "    num_rows: 1000\n",
      "}) ['Tony Goldwyn', 'Goldwyn']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:59:46.072677Z",
     "start_time": "2024-09-05T12:59:45.888693Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from agent.utils.qa import em_f1_score, normalize_answer, multi_ref_score\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "for idx, sample in enumerate(dataset):\n",
    "        \n",
    "\n",
    "    cur_em = []\n",
    "    cur_f1 = []\n",
    "    cur_precesion = []\n",
    "    cur_recall = []\n",
    "    predictions = [sample[\"prediction\"]]\n",
    "    predictions = [prediction.split(\"FINAL ANSWER:\")[-1].strip() for prediction in predictions]\n",
    "\n",
    "    while len(predictions) < 4:\n",
    "        predictions.append(predictions[-1])\n",
    "    \n",
    "    sample[\"answer\"] = [normalize_answer(answer) for answer in sample[\"answer\"]]\n",
    "    # sample[\"answer\"] = normalize_answer(sample[\"answer\"])\n",
    "    predictions = [normalize_answer(prediction) for prediction in predictions]\n",
    "\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "\n",
    "        em, f1, precision, recall = multi_ref_score(prediction, sample['answer'])\n",
    "\n",
    "        cur_em.append(em)\n",
    "        cur_f1.append(f1)\n",
    "        cur_precesion.append(precision)\n",
    "        cur_recall.append(recall)\n",
    "        \n",
    "        # # # early stop\n",
    "        stop = (predictions[idx] == predictions[idx - 1])\n",
    "\n",
    "        if em or stop:\n",
    "            cur_em.extend([em] * (4 - idx - 1))\n",
    "            cur_f1.extend([f1] * (4 - idx - 1))\n",
    "            cur_precesion.extend([precision] * (4 - idx - 1))\n",
    "            cur_recall.extend([recall] * (4 - idx - 1))\n",
    "            break\n",
    "    \n",
    "\n",
    "    em_scores.append(cur_em)\n",
    "    f1_scores.append(cur_f1)\n",
    "    precision_scores.append(cur_precesion)\n",
    "    recall_scores.append(cur_recall)\n",
    "    \n",
    "\n",
    "# output mean of each column of scores\n",
    "em_means = np.array(em_scores).mean(axis=0)\n",
    "em_means = np.round(em_means* 100, decimals=1)\n",
    "\n",
    "f1_means = np.array(f1_scores).mean(axis=0)\n",
    "f1_means = np.round(f1_means* 100, decimals=1)\n",
    "\n",
    "precision_means = np.array(precision_scores).mean(axis=0)\n",
    "precision_means = np.round(precision_means* 100, decimals=1)\n",
    "\n",
    "recall_means = np.array(recall_scores).mean(axis=0)\n",
    "recall_means = np.round(recall_means* 100, decimals=1)\n",
    "\n",
    "print(f\"em_means: {em_means}\\n\", f\"f1_means: {f1_means}\\n\", f\"precision_means: {precision_means}\\n\", f\"recall_means: {recall_means}\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em_means: [44.4 44.4 44.4 44.4]\n",
      " f1_means: [58.3 58.3 58.3 58.3]\n",
      " precision_means: [58.8 58.8 58.8 58.8]\n",
      " recall_means: [61.6 61.6 61.6 61.6]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
