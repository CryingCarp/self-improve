{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage, SystemMessage\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"cot\"\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, base_url=\"https://api.chsdw.top/v1\", top_p=1, model=\"gpt-4o-mini\")\n",
    "\n",
    "# Load prompt\n",
    "def load_prompt(dataset: str, mode: str):\n",
    "    file_path = \"../prompts/{}/{}.md\".format(dataset, mode)\n",
    "    with open(file_path, 'r', encoding='utf-8') as fp:\n",
    "        prompt = fp.read().strip() + \"\\n\\n\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# 并行处理\n",
    "import asyncio\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "async def cot(item, messages: list[BaseMessage], llm: ChatOpenAI, dataset_name:str=\"hotpot_qa\") -> str:\n",
    "    if dataset_name == \"hotpot_qa\":\n",
    "        question_message = HumanMessage(content=\"Question: \" + item[\"question\"])\n",
    "    elif dataset_name == \"toxicity\":\n",
    "        question_message = HumanMessage(content=item[\"prompt\"][\"text\"])\n",
    "    try:\n",
    "        result = await llm.ainvoke(messages+[question_message])\n",
    "        return result.content\n",
    "    except Exception as e:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HotpotQA 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"hotpot_qa\"\n",
    "mode = \"cot\"\n",
    "num_test_sample = 200\n",
    "system_message = SystemMessage(content=\"Answer the following questions. Remember your answer should always end with \\\"So the FINAL ANSWER is: <answer>\\\"\")\n",
    "prompt = load_prompt(dataset_name, mode)\n",
    "prompt_message = HumanMessage(content=prompt)\n",
    "messages = [system_message, prompt_message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=f\"../data/{dataset_name}.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await asyncio.gather(*(cot(item, messages=messages, llm=llm) for item in dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = f\"/Users/ariete/Projects/self-improve/output/{dataset_name}\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "with open (\"/Users/ariete/Projects/self-improve/output/{}/{}_{}.json\".format(dataset_name, num_test_sample, mode), \"w\") as f:\n",
    "    for idx, result in enumerate(results):\n",
    "        f.write(json.dumps({\"idx\": idx, \"question\": dataset[idx][\"question\"], \"answer\":dataset[idx][\"answer\"], \"python code\": results[idx]}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gsm8k 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"gsm8k\"\n",
    "mode = \"pot\"\n",
    "num_test_sample = 200\n",
    "system_message = SystemMessage(content=\"# Write Python Code to solve the following questions. Store your result as a variable named 'answer'. You should follow the format of the prompt below.\")\n",
    "prompt = load_prompt(dataset_name, mode)\n",
    "prompt_message = HumanMessage(content=prompt)\n",
    "messages = [system_message, prompt_message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=f\"../data/{dataset_name}.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "dataset = dataset.map(lambda example: {\"question\": example[\"question\"], \"answer\": example[\"answer\"].split(\"#### \")[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_code(content:str) -> str:\n",
    "    code_match = re.search(r\"```python\\n(.*)\\n```\", content, re.DOTALL)\n",
    "    if code_match:\n",
    "        code = code_match.group(1).strip()  # 提取匹配的代码并去除前后的空白字符\n",
    "        return code\n",
    "    else:\n",
    "        return \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await asyncio.gather(*(cot(item, messages=messages, llm=llm) for item in dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(results)):\n",
    "    dataset[idx][\"python code\"] = extract_code(results[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "python = PythonREPL()\n",
    "prediction = []\n",
    "for result in results:\n",
    "    prediction.append(python.run(extract_code(result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = f\"/Users/ariete/Projects/self-improve/output/{dataset_name}\"\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "with open (\"/Users/ariete/Projects/self-improve/output/{}/{}_{}.json\".format(dataset_name, num_test_sample, mode), \"w\") as f:\n",
    "    for idx, result in enumerate(results):\n",
    "        f.write(json.dumps({\"idx\": idx, \"question\": dataset[idx][\"question\"], \"answer\":dataset[idx][\"answer\"], \"python code\": results[idx], \"prediction\": prediction[idx]}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"toxicity\"\n",
    "mode = \"generate\"\n",
    "num_test_sample = 200\n",
    "system_message = SystemMessage(content=\"The user's input is half a sentence, generating the second half of the sentence\")\n",
    "messages = [system_message]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['filename', 'begin', 'end', 'challenging', 'prompt', 'continuation'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"json\", data_files=f\"../data/{dataset_name}.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "# dataset = dataset.map(lambda example: {\"question\": example[\"question\"], \"answer\": example[\"answer\"].split(\"#### \")[-1]})\n",
    "print(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
