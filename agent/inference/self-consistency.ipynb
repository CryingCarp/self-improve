{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T09:48:04.504004Z",
     "start_time": "2024-09-26T09:48:01.809095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from langchain_core.outputs import LLMResult\n",
    "\n",
    "from agent.utils.loader import load_prompt, load_processed_data\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "id": "fd7d6e426b434f67",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T09:48:08.771674Z",
     "start_time": "2024-09-26T09:48:05.298627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_name = 'hotpot_qa'\n",
    "mode = \"self-consistency\"\n",
    "model = \"gpt-4o-mini\"\n",
    "num_samples = 1000\n",
    "top_p = 0.95\n",
    "# 原文使用的gpt-3 温度为0.7， n=10\n",
    "temperature = 0.7\n",
    "seed = 42\n",
    "batch_size = 100\n",
    "n = 10\n",
    "processed_data_path = f\"../../data/processed_data/{dataset_name}.jsonl\"\n",
    "save_results_path = f\"../../output/inference/{model}/{dataset_name}/{mode}/num_samples_{num_samples}_top_p_{top_p}_temperature_{temperature}_seed_{seed}.jsonl\"\n",
    "prompt = load_prompt(dataset_name=dataset_name, mode=mode)\n",
    "dataset = load_processed_data(dataset_name=dataset_name, file_path=processed_data_path)\n",
    "if num_samples > 0:\n",
    "\tdataset = dataset.select(range(num_samples))\n",
    "llm = ChatOpenAI(model=model, top_p=top_p, n=n, temperature=temperature, base_url=\"https://api.chsdw.top/v1\", seed=seed)\n",
    "\n",
    "prompt.pretty_print()\n",
    "print(dataset[0])"
   ],
   "id": "d2c034092f431c9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\miniconda3\\envs\\self-improve\\Lib\\site-packages\\langsmith\\client.py:323: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m System Message \u001B[0m================================\n",
      "\n",
      "Remember your answer should follow previous pattern and format.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. The eastern sector of Colorado orogeny extends into the High Plains. High Plains rise in elevation from around 1,800 to 7,000 ft. FINAL ANSWER: 1,800 to 7,000 ft.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. Milhouse was named after U.S. president Richard Nixon. FINAL ANSWER: Richard Nixon.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture. FINAL ANSWER: The Saimaa Gesture.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: What profession does Nicholas Ray and Elia Kazan have in common?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. Professions of Nicholas Ray are director, screenwriter, and actor. Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor. FINAL ANSWER: director, screenwriter, actor.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Which magazine was started first Arthur's Magazine or First for Women?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. Arthur's Magazine was started in 1844. First for Women was started in 1989. 1844 (Arthur's Magazine) < 1989 (First for Women), so Arthur's Magazine was started first. FINAL ANSWER: Arthur's Magazine.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Let's think step by step. Pavel Urysohn is a mathematician. Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work. FINAL ANSWER: Yes.\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: \u001B[33;1m\u001B[1;3m{question}\u001B[0m\n",
      "{'context': '', 'question': 'Were Scott Derrickson and Ed Wood of the same nationality?', 'answer': ['yes']}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tqdm.asyncio import tqdm, tqdm_asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def vote(candidate: list, split_signal: str) -> str:\n",
    "\tpredictions = [message.split(split_signal) for message in candidate]\n",
    "\treturn max(set(predictions), key=candidate.count)\n",
    "\n",
    "async def inference(item: dict) -> str:\n",
    "    try:\n",
    "        response: LLMResult = await llm.agenerate(messages=[prompt.invoke(input=item)])\n",
    "        candidate = [choice.message.content for choice in response.generations[0]]\n",
    "        if dataset_name in [\"hotpot_qa\", \"trivia_qa\", \"ambig_qa\"]:\n",
    "            result = {**item, \"candidate\": candidate}\n",
    "        elif dataset_name in [\"gsm8k\", \"tabmwp\", \"svamp\"]:\n",
    "            result = {**item, \"candidate\": candidate}\n",
    "        elif dataset_name == \"toxicity\":\n",
    "            result = {**item, \"candidate\": candidate}\n",
    "        else:\n",
    "            result = {**item, \"candidate\": candidate}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        result = {**item, \"prediction\": \"ERROR\"}\n",
    "    return result\n",
    "\n",
    "async def self_consistency_inference() -> None:\n",
    "\tresults = []\n",
    "\tif os.path.exists(save_results_path):\n",
    "\t    with open(save_results_path, 'r') as file:\n",
    "\t        for line in file:\n",
    "\t            results.append(json.loads(line))\n",
    "\telse:\n",
    "\t\tfolder_path = os.path.dirname(save_results_path)\n",
    "\t\tos.makedirs(folder_path, exist_ok=True)\n",
    "\t\n",
    "\tfor idx in tqdm(range(len(results), dataset.num_rows, batch_size)):\n",
    "\t\tbatch = dataset.select(range(idx, min(idx+batch_size, dataset.num_rows)))\n",
    "\t\tresults.extend(await tqdm_asyncio.gather(*(inference(item) for item in batch)))\n",
    "\t\twith open(save_results_path, 'w') as file:\n",
    "\t\t\tfor result in results:\n",
    "\t\t\t\tfile.write(json.dumps(result) + \"\\n\")\n"
   ],
   "id": "b534bd6e3eac64b3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
