{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "a593f9da63efe19a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T14:35:52.298063Z",
     "start_time": "2024-09-22T14:35:52.282271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from agent.utils.loader import load_prompt, load_processed_data\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_core.prompts.chat import BaseMessage\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ],
   "id": "405ae783c6240446",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-22T14:17:16.405607Z",
     "start_time": "2024-09-22T14:17:14.023133Z"
    }
   },
   "source": [
    "dataset_name = 'ambig_qa'\n",
    "mode = \"direct\"\n",
    "model = \"gpt-4o-mini\"\n",
    "num_samples = 1000\n",
    "top_p = 1\n",
    "temperature = 0\n",
    "processed_data_path = f\"../../data/processed_data/{dataset_name}.jsonl\"\n",
    "save_results_path = f\"../../output/inference/{model}/{dataset_name}/{mode}/num_samples_{num_samples}_top_p_{top_p}_temperature_{temperature}.jsonl\"\n",
    "prompt = load_prompt(dataset_name=dataset_name, mode=mode)\n",
    "dataset = load_processed_data(dataset_name=dataset_name, file_path=processed_data_path)\n",
    "llm = ChatOpenAI(model=model, top_p=top_p, temperature=temperature, base_url=\"https://api.chsdw.top/v1\")\n",
    "\n",
    "prompt.pretty_print()\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/langchain_core/_api/beta_decorator.py:87: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: When did men's figure skating become a summer Olympic sport?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: 1908\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: When did the all india workers and peasants party came in to existence?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: November 1925\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Flight that went down in the hudson river?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: US Airways Flight 1549\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Where are most of the world's earthquakes located?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Rim of Fire\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Csi when do grissom and sara reunite?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: series finale\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Who did rizzo go to the dance with?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Kenickie Murdoch\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: What country won the womens curling winter olympics 2018?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Sweden\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Who plays barnaby's wife in midsomer murders series 1-13?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Jane Wymark\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: Who plays 7-9 year old Nelson Mandela in the movie Mandela: Long Walk to Freedom?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: Siza Pini\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: When did the movie coyote ugly come out?\n",
      "\n",
      "==================================\u001B[1m AI Message \u001B[0m==================================\n",
      "\n",
      "A: August 4, 2000\n",
      "\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "Q: \u001B[33;1m\u001B[1;3m{question}\u001B[0m\n",
      "Dataset({\n",
      "    features: ['context', 'question', 'answer'],\n",
      "    num_rows: 2002\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T14:47:00.292095Z",
     "start_time": "2024-09-22T14:46:58.311358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.asyncio import tqdm\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def direct():\n",
    "\tchain = prompt | llm\n",
    "\tresult = []\n",
    "\tif os.path.exists(save_results_path):\n",
    "\t    with open(save_results_path, 'r') as file:\n",
    "\t        for line in file:\n",
    "\t            result.append(json.loads(line))\n",
    "\t\n",
    "\tfor idx in tqdm(range(len(result), num_samples)):\n",
    "\t\ttry:\n",
    "\t\t\tresponse: BaseMessage = await chain.ainvoke(input={\"question\": dataset[idx][\"question\"]})\n",
    "\t\t\tif dataset in [\"hotpot_qa\", \"trivia_qa\", \"ambig_qa\"]:\n",
    "\t\t\t\tresult.append({**dataset[idx], \"prediction\": response.content.split(\"A: \")[-1]})\n",
    "\t\t\telif dataset in [\"gsm9k\", \"tabmwp\", \"svamp\"]:\n",
    "\t\t\t\tresult.append({**dataset[idx], \"prediction\": response.content.split(\"Answer: \")[-1]})\n",
    "\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tresult.append({**dataset[idx], \"prediction\": \"ERROR\"})\n",
    "\t\t\n",
    "\t\tif idx % 100 == 0:\n",
    "\t\t\twith open(save_results_path, 'w') as file:\n",
    "\t\t\t\tfor line in result:\n",
    "\t\t\t\t\tfile.write(json.dumps(line) + '\\n')\n",
    "\t\t\n",
    "asyncio.run(direct())"
   ],
   "id": "43d7fe0e3e67d9b9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/inspect.py:3066: RuntimeWarning: coroutine 'direct' was never awaited\n",
      "  params = OrderedDict((param.name, param) for param in parameters)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "  0%|          | 0/1000 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../output/inference/gpt-4o-mini/ambig_qa/direct/num_samples_1000_top_p_1_temperature_0.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m \t\t\t\t\u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[1;32m     22\u001B[0m \t\t\t\t\tfile\u001B[38;5;241m.\u001B[39mwrite(json\u001B[38;5;241m.\u001B[39mdumps(line) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 24\u001B[0m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdirect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/nest_asyncio.py:30\u001B[0m, in \u001B[0;36m_patch_asyncio.<locals>.run\u001B[0;34m(main, debug)\u001B[0m\n\u001B[1;32m     28\u001B[0m task \u001B[38;5;241m=\u001B[39m asyncio\u001B[38;5;241m.\u001B[39mensure_future(main)\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 30\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtask\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m task\u001B[38;5;241m.\u001B[39mdone():\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/nest_asyncio.py:98\u001B[0m, in \u001B[0;36m_patch_loop.<locals>.run_until_complete\u001B[0;34m(self, future)\u001B[0m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f\u001B[38;5;241m.\u001B[39mdone():\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m     97\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEvent loop stopped before Future completed.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 98\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/asyncio/futures.py:203\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__log_traceback \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 203\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception\u001B[38;5;241m.\u001B[39mwith_traceback(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_exception_tb)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_result\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/asyncio/tasks.py:314\u001B[0m, in \u001B[0;36mTask.__step_run_and_handle_result\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    312\u001B[0m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[1;32m    313\u001B[0m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[0;32m--> 314\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mcoro\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    315\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    316\u001B[0m         result \u001B[38;5;241m=\u001B[39m coro\u001B[38;5;241m.\u001B[39mthrow(exc)\n",
      "Cell \u001B[0;32mIn[6], line 20\u001B[0m, in \u001B[0;36mdirect\u001B[0;34m()\u001B[0m\n\u001B[1;32m     17\u001B[0m result\u001B[38;5;241m.\u001B[39mappend(response)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m idx \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 20\u001B[0m \t\u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msave_results_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mw\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m     21\u001B[0m \t\t\u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m result:\n\u001B[1;32m     22\u001B[0m \t\t\tfile\u001B[38;5;241m.\u001B[39mwrite(json\u001B[38;5;241m.\u001B[39mdumps(line) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/IPython/core/interactiveshell.py:324\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    318\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    319\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    321\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    322\u001B[0m     )\n\u001B[0;32m--> 324\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../../output/inference/gpt-4o-mini/ambig_qa/direct/num_samples_1000_top_p_1_temperature_0.jsonl'"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
