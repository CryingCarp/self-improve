{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:01.811971Z",
     "start_time": "2024-12-17T12:54:57.736594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from agent.utils.loader import load_processed_data\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"self-correct\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\""
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:04.614693Z",
     "start_time": "2024-12-17T12:55:01.821980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meta_info = {\n",
    "\t\"dataset_name\": 'gsm8k',\n",
    "\t\"mode\": \"self-improve\",\n",
    "\t\"base_mode\": \"pot\",\n",
    "\t\"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "\t\"num_samples\": -1,\n",
    "\t\"top_p\": 0.95,\n",
    "\t\"temperature\": 0,\n",
    "\t\"seed\": 42,\n",
    "\t\"batch_size\": 100\n",
    "}\n",
    "assert meta_info[\"mode\"] == \"self-improve\"\n",
    "assert meta_info[\"dataset_name\"] in [\"gsm8k\", \"math\", \"gsmhard\", \"tabmwp\", \"svamp\"], \"Invalid dataset name\"\n",
    "\n",
    "if meta_info[\"base_mode\"] == \"cot\":\n",
    "\tprocessed_data_path = f\"../../../output/inference/{meta_info['model']}/{meta_info['dataset_name']}/cot/num_samples_1000_top_p_0.95_temperature_0_seed_42.jsonl\"\n",
    "else:\n",
    "\tprocessed_data_path = f\"../../../data/processed_data/{meta_info['dataset_name']}.jsonl\"\n",
    "\n",
    "dataset = load_processed_data(dataset_name=meta_info[\"dataset_name\"], file_path=processed_data_path)\n",
    "if meta_info[\"base_mode\"] == \"cot\":\n",
    "\tdataset = dataset.remove_columns([\"prediction\", 'generation'])\n",
    "model = ChatOpenAI(\n",
    "\tmodel_name=meta_info[\"model\"],\n",
    "\ttop_p=meta_info[\"top_p\"],\n",
    "\ttemperature=meta_info[\"temperature\"],\n",
    "\tseed=meta_info[\"seed\"],\n",
    "\topenai_api_base=\"https://api.chsdw.top/v1\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "if meta_info[\"num_samples\"] > 0:\n",
    "\tdataset = dataset.select(range(meta_info[\"num_samples\"]))\n",
    "print(dataset[10])"
   ],
   "id": "899a728a48f65d10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "788fe819f4f1425da083c09aacdd548e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': '', 'question': 'A new program had 60 downloads in the first month. The number of downloads in the second month was three times as many as the downloads in the first month, but then reduced by 30% in the third month. How many downloads did the program have total over the three months?', 'answer': '366'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:27.037973Z",
     "start_time": "2024-12-17T12:55:26.944203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langgraph.managed.is_last_step import RemainingSteps\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "\tquestion: str\n",
    "\tguidance: str\n",
    "\tremaining_steps: RemainingSteps\n",
    "\tmessages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "\tinitial_answer: str\n",
    "\tfusion: str\n",
    "\tprediction: str"
   ],
   "id": "5e69db7d961b70ae",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:30.434150Z",
     "start_time": "2024-12-17T12:55:30.426351Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "guidance_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"system\",\n",
    "\t\t\t\"You are a question planner and error prone points identifier. Given a question or problem, your job is to come up with a step by step plan, and you should also identify the most error-prone points for each step, following them closely behind each step. The plan and the error prone points will then be used to guide the selection of subsequent tools and the corresponding tool inputs. The tool results should always be considered as reliable. Do not add any superfluous steps. Make sure that each step has all the information needed - do not skip steps. You should focus on the logic of how to solve the problem, rather than actually solving it.\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"user\",\n",
    "\t\t\t\"Question: {question}\"\n",
    "\t\t)\n",
    "\t])\n",
    "guidance_generator = guidance_prompt | model\n",
    "\n",
    "\n",
    "async def guidance_node(state: State) -> State:\n",
    "\tassert state[\"question\"] is not None, \"Question is required\"\n",
    "\tquestion:str = state[\"question\"]\n",
    "\tguidance:AIMessage = await guidance_generator.ainvoke(input={\"question\": question})\n",
    "\tstate[\"guidance\"] = guidance.content\n",
    "\treturn state"
   ],
   "id": "bb7f5744be938c0f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:35.046278Z",
     "start_time": "2024-12-17T12:55:32.494936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_community.utilities.wikidata import WikidataAPIWrapper\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from agent.utils.tools import GoogleSearchTool, GoogleKnowledgeGraphTool, WikidataTool, WikipediaTool, python_interpreter\n",
    "\n",
    "google_search = GoogleSearchTool()\n",
    "google_knowledge_graph = GoogleKnowledgeGraphTool()\n",
    "wikidata = WikidataTool(api_wrapper=WikidataAPIWrapper())\n",
    "wikipedia = WikipediaTool()\n",
    "tools = [google_search, google_knowledge_graph, wikipedia, wikidata, python_interpreter]\n",
    "\n",
    "model_with_tools = model.bind_tools(tools)\n"
   ],
   "id": "7dba393e7f0c7193",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:55:36.926089Z",
     "start_time": "2024-12-17T12:55:36.914472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from typing import Literal\n",
    "\n",
    "critique_prompt = ChatPromptTemplate.from_messages([\n",
    "\t(\n",
    "\t\t\"system\",\n",
    "\t\t\"You are a reactive agent. Given a question or problem, your job is to select the appropriate tools to answer the question or solve the problem. You should consider the guidance provided by the question planner and error prone points identifier, and the tool results are reliable. If you find the answer from the tool results, you should provide the answer.\"\n",
    "\t),\n",
    "\t(\n",
    "\t\t\"user\",\n",
    "\t\t\"Question: {question}\"\n",
    "\t\t\"Guidance: {guidance}\"\n",
    "\t)\n",
    "])\n",
    "\n",
    "async def critique_node(state: State):\n",
    "\tassert state[\"question\"] is not None, \"Question is required\"\n",
    "\tassert state[\"guidance\"] is not None, \"Guidance is required\"\n",
    "\tquestion:str = state[\"question\"]\n",
    "\tguidance:str = state[\"guidance\"]\n",
    "\tmessages:list[BaseMessage] = []\n",
    "\tif len(state[\"messages\"]) == 0:\n",
    "\t\tmessages = critique_prompt.invoke(input={\"question\": question, \"guidance\": guidance}).to_messages()\n",
    "\t\tcritique:AIMessage = await model_with_tools.ainvoke(input=messages)\n",
    "\t\tmessages.append(critique)\n",
    "\telse:\n",
    "\t\tcritique:AIMessage = await model_with_tools.ainvoke(input=state[\"messages\"])\n",
    "\t\tmessages.append(critique)\n",
    "\treturn {\"messages\": messages}\n",
    "\n",
    "# Define our tool node\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "fusion_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"system\",\n",
    "\t\t\t\"You are a fusion agent. Given a question or problem and based on the critique process, your job is to fuse the tool results and then revise your final answer. \"\n",
    "\t\t\t\"Your response should contains two part, the first part is the fusion of the Revising Process and the second part is the final answer. In the fusion part, you should extract the information from the tool result and also indicate how you obtained the information.(which tool, which part of the result) In the final answer, \"\n",
    "\t\t\t\"do not include any explanations, context, or additional information. Just focus on delivering the exact answer as concisely as possible!!! \"\n",
    "\t\t\t\"There is no need to answer the question in the form of a complete sentence, just provide the answer in the form of a noun, time, entity, single number, yes or no, etc.\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"placeholder\",\n",
    "\t\t\t\"{messages}\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"user\",\n",
    "\t\t\t\"Now based on the previous information, please fuse the tool results and revise your answer. Use the XML tag <fusion></fusion> to indicate the fusion part and <answer></answer> to indicate the final answer part.\"\n",
    "\t\t)\n",
    "\t])\n",
    "fusion_generator = fusion_prompt | model\n",
    "\n",
    "async def fusion_node(state: State) -> State:\n",
    "\tassert state[\"question\"] is not None, \"Question is required\"\n",
    "\tassert state[\"guidance\"] is not None, \"Guidance is required\"\n",
    "\tcritique_messages:Sequence[BaseMessage] = state[\"messages\"][1:]\n",
    "\tresponse:AIMessage = await fusion_generator.ainvoke(input={\"messages\": critique_messages})\n",
    "\tfusion_matches = re.findall(r\"<fusion>(.*?)</fusion>\", response.content, re.DOTALL)\n",
    "\tanswer_matches = re.findall(r\"<answer>(.*?)</answer>\", response.content, re.DOTALL)\n",
    "\tif fusion_matches:\n",
    "\t\tstate[\"fusion\"] = fusion_matches[0]\n",
    "\telse:\n",
    "\t\tstate[\"fusion\"] = response.content\n",
    "\tif answer_matches:\n",
    "\t\tstate[\"prediction\"] = answer_matches[0]\n",
    "\telse:\n",
    "\t\tstate[\"prediction\"] = \"None\"\n",
    "\n",
    "\treturn state\n",
    "\n",
    "# Define the conditional edge that determines whether to continue or not\n",
    "def should_continue(state: State) -> Literal[\"fuse\", \"tools\"]:\n",
    "\tif state[\"remaining_steps\"] <= 2:\n",
    "\t\treturn \"fuse\"\n",
    "\tmessages = state[\"messages\"]\n",
    "\tlast_message = messages[-1]\n",
    "\t# If there is no function call, then we finish\n",
    "\tif last_message.tool_calls:\n",
    "\t\treturn \"tools\"\n",
    "\t# Otherwise if there is, we continue\n",
    "\telse:\n",
    "\t\treturn \"fuse\""
   ],
   "id": "495ca8c028baba27",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:56:13.474703Z",
     "start_time": "2024-12-17T12:56:12.467446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"guide\", guidance_node)\n",
    "workflow.add_node(\"critique\", critique_node)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.add_node(\"fuse\", fusion_node)\n",
    "\n",
    "workflow.set_entry_point(\"guide\")\n",
    "workflow.add_edge(\"guide\", \"critique\")\n",
    "workflow.add_edge(\"tools\", \"critique\")\n",
    "workflow.add_conditional_edges(\"critique\", should_continue)\n",
    "workflow.add_edge(\"fuse\", \"__end__\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ],
   "id": "39a7af6979b806ef",
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fd177be3c8ac3d98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:45:52.028925Z",
     "start_time": "2024-12-17T10:45:52.016617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.asyncio import tqdm_asyncio, tqdm\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import nest_asyncio\n",
    "\n",
    "# 配置logger\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,  # 设置日志级别\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # 设置日志格式\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"inference.log\"),  # 将日志输出到文件\n",
    "        logging.StreamHandler()  # 也输出到控制台\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"InferenceLogger\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "results = []\n",
    "batch_size = 100\n",
    "save_results_path = f\"../../../output/inference/{meta_info['model']}/{meta_info['dataset_name']}/{meta_info['mode']}/{meta_info['base_mode']}_num_samples_{meta_info['num_samples']}_top_p_{meta_info['top_p']}_temperature_{meta_info['temperature']}_seed_{meta_info['seed']}.jsonl\"\n",
    "\n",
    "async def process(item):\n",
    "    try:\n",
    "        state = await app.ainvoke({**item, \"messages\": []})\n",
    "        state[\"messages\"] = [message.pretty_repr() for message in state[\"messages\"]]\n",
    "        logger.info(f\"Processed item: {item}\")\n",
    "        return {**item, **state}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing item: {item}. Error: {e}\")\n",
    "        return {**item, \"prediction\": \"None\"}\n",
    "\n",
    "async def self_improve_inference() -> None:\n",
    "    error_indices = []  # 用于记录包含 \"ERROR\" 的条目索引\n",
    "\n",
    "    # 读取已有结果或初始化文件\n",
    "    if os.path.exists(save_results_path):\n",
    "        logger.info(f\"Loading existing results from {save_results_path}\")\n",
    "        with open(save_results_path, 'r') as file:\n",
    "            for idx, line in enumerate(file):\n",
    "                result = json.loads(line)\n",
    "                results.append(result)\n",
    "                # 检查是否存在 \"prediction: ERROR\"\n",
    "                if \"None\" == result.get(\"prediction\"):\n",
    "                    error_indices.append(idx)\n",
    "    else:\n",
    "        folder_path = os.path.dirname(save_results_path)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        logger.info(f\"Created directory for results: {folder_path}\")\n",
    "\n",
    "    # 重新推理错误的数据\n",
    "    if error_indices:\n",
    "        logger.warning(f\"Found {len(error_indices)} ERROR entries. Retrying inference...\")\n",
    "        error_data = [dataset[idx] for idx in error_indices]\n",
    "        new_results = await tqdm_asyncio.gather(*(process(item) for item in error_data))\n",
    "        # 更新原始结果\n",
    "        for i, new_result in zip(error_indices, new_results):\n",
    "            results[i] = new_result\n",
    "\n",
    "    # 使用tqdm进度条显示进度，设置desc为提示信息\n",
    "    bar = tqdm(total=dataset.num_rows, desc=\"Processing batches\", position=0, dynamic_ncols=True)\n",
    "\n",
    "    for idx in range(len(results), dataset.num_rows, batch_size):\n",
    "        batch = dataset.select(range(idx, min(idx + batch_size, dataset.num_rows)))\n",
    "        batch_results = await tqdm_asyncio.gather(*(process(item) for item in batch))\n",
    "        results.extend(batch_results)\n",
    "\n",
    "        # 更新进度条，进度条更新为当前批次的长度\n",
    "        bar.update(batch_size)\n",
    "        logger.info(f\"Processed batch starting at index {idx}\")\n",
    "\n",
    "        # 保存结果\n",
    "        with open(save_results_path, 'w') as file:\n",
    "            for result in results:\n",
    "                file.write(json.dumps(result) + \"\\n\")\n",
    "        logger.info(f\"Saved results to {save_results_path}\")\n",
    "\n",
    "    bar.close()  # 完成处理后关闭进度条\n"
   ],
   "id": "a147e487a346748f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:52:27.491699Z",
     "start_time": "2024-12-17T10:45:53.285078Z"
    }
   },
   "cell_type": "code",
   "source": "await self_improve_inference()",
   "id": "c6e7e2b128c439a4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 31/58 [03:30<01:41,  3.74s/it]2024-12-17 18:49:27,666 - ERROR - Error processing item: {'context': '', 'question': 'In 2017, what was 3/4th of the organization that also has a Center for Veterinary Medicine as well as part of the U.S. Department of Health and Human Services, spent on?', 'answer': ['Prescription Drug User Fee Act']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 64%|██████▍   | 37/58 [03:46<00:55,  2.62s/it]2024-12-17 18:49:41,854 - ERROR - Error processing item: {'context': '', 'question': \"Who currently has more store locations? Bearno's or Patxi's Chicago Pizza?\", 'answer': [\"Bearno's Pizza\"]}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 71%|███████   | 41/58 [03:55<00:43,  2.55s/it]2024-12-17 18:49:52,031 - ERROR - Error processing item: {'context': '', 'question': 'Where is the company that owns thanKing Horse pub restaurant chain based ?', 'answer': ['Bury St Edmunds,']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 76%|███████▌  | 44/58 [04:28<01:55,  8.28s/it]2024-12-17 18:50:22,313 - ERROR - Error processing item: {'context': '', 'question': 'What movie is the the Spinning turtle attraction in the worlds 21st largest theme park based off of?', 'answer': ['Finding Nemo']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 78%|███████▊  | 45/58 [04:28<01:18,  6.05s/it]2024-12-17 18:50:24,485 - ERROR - Error processing item: {'context': '', 'question': 'Chris Williams last played for which football club from the National League North?', 'answer': ['Salford City Football Club']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 79%|███████▉  | 46/58 [04:31<00:58,  4.89s/it]2024-12-17 18:50:28,776 - ERROR - Error processing item: {'context': '', 'question': 'Chris Jones is a semi-professional footballer, who played with what goalkeeper for Derby County when he was with Yorkshire?', 'answer': ['Scott Paul Carson']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 83%|████████▎ | 48/58 [04:37<00:38,  3.82s/it]2024-12-17 18:50:39,567 - ERROR - Error processing item: {'context': '', 'question': 'Who is the psychologist who wrote about the disciple of the person known as the \"Wild Woman of Buttle\"?', 'answer': ['James G. Kiernan']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 90%|████████▉ | 52/58 [05:00<00:28,  4.68s/it]2024-12-17 18:50:55,945 - ERROR - Error processing item: {'context': '', 'question': 'What amount was the settlement that the character from the Son of al Quada got in 2017?', 'answer': ['$10.5 million']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 91%|█████████▏| 53/58 [05:02<00:20,  4.06s/it]2024-12-17 18:50:57,452 - ERROR - Error processing item: {'context': '', 'question': 'Peter Dhao created a websiteto reflect worldwide views. What was the slogan of the site he created ?', 'answer': ['media for the 65.8 million']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 93%|█████████▎| 54/58 [05:04<00:13,  3.39s/it]2024-12-17 18:50:59,269 - ERROR - Error processing item: {'context': '', 'question': 'What is the inhabitant of the city where  122nd SS-Standarte was formed in2014', 'answer': ['276,170 inhabitants']}. Error: Error code: 429 - {'error': {'message': '当前分组上游负载已饱和，请稍后再试 (request id: 20241217185033617361608oKhk3lYv)', 'type': 'tokens', 'param': '', 'code': 'rate_limit_exceeded'}}\n",
      " 97%|█████████▋| 56/58 [05:23<00:13,  6.96s/it]2024-12-17 18:51:35,755 - ERROR - Error processing item: {'context': '', 'question': 'Which Kentucky Writers Hall of Fame author has had works published by Dim Gray Bar Press?', 'answer': ['Wendell Berry']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      " 98%|█████████▊| 57/58 [05:42<00:10, 10.47s/it]2024-12-17 18:52:27,484 - ERROR - Error processing item: {'context': '', 'question': 'Who was one of the stars who played the two oldest children in a TV series which had a 2010 movie based on it?', 'answer': ['Michael Seater']}. Error: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\n",
      "100%|██████████| 58/58 [06:34<00:00,  6.80s/it]\n",
      "Processing batches:   0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T10:52:42.077207Z",
     "start_time": "2024-12-17T10:52:42.007714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存结果\n",
    "with open(save_results_path, 'w') as file:\n",
    "\tfor result in results:\n",
    "\t\tfile.write(json.dumps(result) + \"\\n\")\n",
    "logger.info(f\"Saved results to {save_results_path}\")"
   ],
   "id": "bf69bff52eca4e97",
   "outputs": [],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
