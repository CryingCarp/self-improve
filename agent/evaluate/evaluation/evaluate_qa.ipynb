{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hotpot_qa"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-23T07:38:32.900327Z",
     "start_time": "2024-11-23T07:38:28.945811Z"
    }
   },
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_name: str = \"hotpot_qa\"\n",
    "dataset = load_dataset(\"json\",\n",
    "                       data_files=\"/Users/ariete/Projects/self-improve/output/inference/gpt-4o-mini/hotpot_qa/self-improve/num_samples_100_top_p_0.95_temperature_0_seed_42.jsonl\",\n",
    "                       split=\"train\")\n",
    "if dataset_name == \"trivia_qa\":\n",
    "\tdataset = dataset.map(lambda x: {\"answer\": x[\"answer\"][\"normalized_aliases\"]})\n",
    "print(dataset, dataset[0][\"answer\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8305fbf8ab14383984407583438c3f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to load JSON from file '/Users/ariete/Projects/self-improve/output/inference/gpt-4o-mini/hotpot_qa/self-improve/num_samples_100_top_p_0.95_temperature_0_seed_42.jsonl' with error <class 'pyarrow.lib.ArrowInvalid'>: JSON parse error: Column(/step/[]/tool_results/[]/[]) changed from string to array in row 0\n"
     ]
    },
    {
     "ename": "DatasetGenerationError",
     "evalue": "An error occurred while generating the dataset",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:160\u001B[0m, in \u001B[0;36mJson._generate_tables\u001B[0;34m(self, files)\u001B[0m\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(\n\u001B[1;32m    158\u001B[0m         file, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mencoding_errors\n\u001B[1;32m    159\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m--> 160\u001B[0m         df \u001B[38;5;241m=\u001B[39m \u001B[43mpandas_read_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:38\u001B[0m, in \u001B[0;36mpandas_read_json\u001B[0;34m(path_or_buf, **kwargs)\u001B[0m\n\u001B[1;32m     37\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype_backend\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpyarrow\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 38\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pandas/io/json/_json.py:815\u001B[0m, in \u001B[0;36mread_json\u001B[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 815\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjson_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pandas/io/json/_json.py:1025\u001B[0m, in \u001B[0;36mJsonReader.read\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1024\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1025\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_object_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype_backend \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pandas/io/json/_json.py:1051\u001B[0m, in \u001B[0;36mJsonReader._get_object_parser\u001B[0;34m(self, json)\u001B[0m\n\u001B[1;32m   1050\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mframe\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1051\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[43mFrameParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1053\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m typ \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mseries\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m obj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pandas/io/json/_json.py:1187\u001B[0m, in \u001B[0;36mParser.parse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1185\u001B[0m \u001B[38;5;129m@final\u001B[39m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m-> 1187\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1189\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pandas/io/json/_json.py:1403\u001B[0m, in \u001B[0;36mFrameParser._parse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1401\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m   1402\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj \u001B[38;5;241m=\u001B[39m DataFrame(\n\u001B[0;32m-> 1403\u001B[0m         \u001B[43mujson_loads\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjson\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprecise_float\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mprecise_float\u001B[49m\u001B[43m)\u001B[49m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1404\u001B[0m     )\n\u001B[1;32m   1405\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m orient \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplit\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: Trailing data",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mArrowInvalid\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/builder.py:1853\u001B[0m, in \u001B[0;36mArrowBasedBuilder._prepare_split_single\u001B[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001B[0m\n\u001B[1;32m   1852\u001B[0m _time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m-> 1853\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtable\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1854\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mmax_shard_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mand\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mwriter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_bytes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmax_shard_size\u001B[49m\u001B[43m:\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:163\u001B[0m, in \u001B[0;36mJson._generate_tables\u001B[0;34m(self, files)\u001B[0m\n\u001B[1;32m    162\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to load JSON from file \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m with error \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m df\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mtolist() \u001B[38;5;241m==\u001B[39m [\u001B[38;5;241m0\u001B[39m]:\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/packaged_modules/json/json.py:137\u001B[0m, in \u001B[0;36mJson._generate_tables\u001B[0;34m(self, files)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 137\u001B[0m     pa_table \u001B[38;5;241m=\u001B[39m \u001B[43mpaj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_json\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[43m        \u001B[49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBytesIO\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mread_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpaj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mReadOptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblock_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mblock_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    139\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pyarrow/_json.pyx:308\u001B[0m, in \u001B[0;36mpyarrow._json.read_json\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pyarrow/error.pxi:155\u001B[0m, in \u001B[0;36mpyarrow.lib.pyarrow_internal_check_status\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/pyarrow/error.pxi:92\u001B[0m, in \u001B[0;36mpyarrow.lib.check_status\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mArrowInvalid\u001B[0m: JSON parse error: Column(/step/[]/tool_results/[]/[]) changed from string to array in row 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mDatasetGenerationError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      3\u001B[0m dataset_name:\u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhotpot_qa\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mload_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mjson\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_files\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m/Users/ariete/Projects/self-improve/output/inference/gpt-4o-mini/hotpot_qa/self-improve/num_samples_100_top_p_0.95_temperature_0_seed_42.jsonl\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msplit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtrain\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dataset_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrivia_qa\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m      6\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mmap(\u001B[38;5;28;01mlambda\u001B[39;00m x: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m: x[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnormalized_aliases\u001B[39m\u001B[38;5;124m\"\u001B[39m]})\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/load.py:2096\u001B[0m, in \u001B[0;36mload_dataset\u001B[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001B[0m\n\u001B[1;32m   2093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m builder_instance\u001B[38;5;241m.\u001B[39mas_streaming_dataset(split\u001B[38;5;241m=\u001B[39msplit)\n\u001B[1;32m   2095\u001B[0m \u001B[38;5;66;03m# Download and prepare data\u001B[39;00m\n\u001B[0;32m-> 2096\u001B[0m \u001B[43mbuilder_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdownload_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2097\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2098\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdownload_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdownload_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2099\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2102\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2104\u001B[0m \u001B[38;5;66;03m# Build dataset for splits\u001B[39;00m\n\u001B[1;32m   2105\u001B[0m keep_in_memory \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m   2106\u001B[0m     keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(builder_instance\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size)\n\u001B[1;32m   2107\u001B[0m )\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/builder.py:924\u001B[0m, in \u001B[0;36mDatasetBuilder.download_and_prepare\u001B[0;34m(self, output_dir, download_config, download_mode, verification_mode, dl_manager, base_path, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_proc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    923\u001B[0m     prepare_split_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_proc\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m num_proc\n\u001B[0;32m--> 924\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_download_and_prepare\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    925\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdl_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdl_manager\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    926\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverification_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverification_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    927\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mprepare_split_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    928\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdownload_and_prepare_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    929\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    930\u001B[0m \u001B[38;5;66;03m# Sync info\u001B[39;00m\n\u001B[1;32m    931\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mdataset_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(split\u001B[38;5;241m.\u001B[39mnum_bytes \u001B[38;5;28;01mfor\u001B[39;00m split \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39msplits\u001B[38;5;241m.\u001B[39mvalues())\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/builder.py:999\u001B[0m, in \u001B[0;36mDatasetBuilder._download_and_prepare\u001B[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001B[0m\n\u001B[1;32m    995\u001B[0m split_dict\u001B[38;5;241m.\u001B[39madd(split_generator\u001B[38;5;241m.\u001B[39msplit_info)\n\u001B[1;32m    997\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    998\u001B[0m     \u001B[38;5;66;03m# Prepare split will record examples associated to the split\u001B[39;00m\n\u001B[0;32m--> 999\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_split\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mprepare_split_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1000\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1001\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\n\u001B[1;32m   1002\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot find data file. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1003\u001B[0m         \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmanual_download_instructions \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1004\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mOriginal error:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1005\u001B[0m         \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)\n\u001B[1;32m   1006\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/builder.py:1740\u001B[0m, in \u001B[0;36mArrowBasedBuilder._prepare_split\u001B[0;34m(self, split_generator, file_format, num_proc, max_shard_size)\u001B[0m\n\u001B[1;32m   1738\u001B[0m job_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1739\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m pbar:\n\u001B[0;32m-> 1740\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mjob_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_split_single\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1741\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgen_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgen_kwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mjob_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_prepare_split_args\u001B[49m\n\u001B[1;32m   1742\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1743\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdone\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1744\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcontent\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/datasets/builder.py:1896\u001B[0m, in \u001B[0;36mArrowBasedBuilder._prepare_split_single\u001B[0;34m(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\u001B[0m\n\u001B[1;32m   1894\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, DatasetGenerationError):\n\u001B[1;32m   1895\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[0;32m-> 1896\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetGenerationError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while generating the dataset\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m   1898\u001B[0m \u001B[38;5;28;01myield\u001B[39;00m job_id, \u001B[38;5;28;01mTrue\u001B[39;00m, (total_num_examples, total_num_bytes, writer\u001B[38;5;241m.\u001B[39m_features, num_shards, shard_lengths)\n",
      "\u001B[0;31mDatasetGenerationError\u001B[0m: An error occurred while generating the dataset"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-14T09:22:55.841030Z",
     "start_time": "2024-11-14T09:22:55.807619Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from agent.utils.qa import normalize_answer, multi_ref_score\n",
    "\n",
    "em_scores = []\n",
    "f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "for idx, sample in enumerate(dataset.select(range(100))):\n",
    "\n",
    "\tcur_em = []\n",
    "\tcur_f1 = []\n",
    "\tcur_precesion = []\n",
    "\tcur_recall = []\n",
    "\tpredictions = [sample[\"prediction\"]]\n",
    "\tpredictions = [prediction.split(\"FINAL ANSWER:\")[-1].strip() for prediction in predictions]\n",
    "\n",
    "\twhile len(predictions) < 4:\n",
    "\t\tpredictions.append(predictions[-1])\n",
    "\n",
    "\tsample[\"answer\"] = [normalize_answer(answer) for answer in sample[\"answer\"]]\n",
    "\t# sample[\"answer\"] = normalize_answer(sample[\"answer\"])\n",
    "\tpredictions = [normalize_answer(prediction) for prediction in predictions]\n",
    "\n",
    "\tfor idx, prediction in enumerate(predictions):\n",
    "\n",
    "\t\tem, f1, precision, recall = multi_ref_score(prediction, sample['answer'])\n",
    "\n",
    "\t\tcur_em.append(em)\n",
    "\t\tcur_f1.append(f1)\n",
    "\t\tcur_precesion.append(precision)\n",
    "\t\tcur_recall.append(recall)\n",
    "\n",
    "\t\t# # # early stop\n",
    "\t\tstop = (predictions[idx] == predictions[idx - 1])\n",
    "\n",
    "\t\tif em or stop:\n",
    "\t\t\tcur_em.extend([em] * (4 - idx - 1))\n",
    "\t\t\tcur_f1.extend([f1] * (4 - idx - 1))\n",
    "\t\t\tcur_precesion.extend([precision] * (4 - idx - 1))\n",
    "\t\t\tcur_recall.extend([recall] * (4 - idx - 1))\n",
    "\t\t\tbreak\n",
    "\n",
    "\tem_scores.append(cur_em)\n",
    "\tf1_scores.append(cur_f1)\n",
    "\tprecision_scores.append(cur_precesion)\n",
    "\trecall_scores.append(cur_recall)\n",
    "\n",
    "# output mean of each column of scores\n",
    "em_means = np.array(em_scores).mean(axis=0)\n",
    "em_means = np.round(em_means * 100, decimals=1)\n",
    "\n",
    "f1_means = np.array(f1_scores).mean(axis=0)\n",
    "f1_means = np.round(f1_means * 100, decimals=1)\n",
    "\n",
    "precision_means = np.array(precision_scores).mean(axis=0)\n",
    "precision_means = np.round(precision_means * 100, decimals=1)\n",
    "\n",
    "recall_means = np.array(recall_scores).mean(axis=0)\n",
    "recall_means = np.round(recall_means * 100, decimals=1)\n",
    "\n",
    "print(f\"em_means: {em_means}\\n\", f\"f1_means: {f1_means}\\n\", f\"precision_means: {precision_means}\\n\",\n",
    "      f\"recall_means: {recall_means}\\n\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "em_means: [14. 14. 14. 14.]\n",
      " f1_means: [31.1 31.1 31.1 31.1]\n",
      " precision_means: [27. 27. 27. 27.]\n",
      " recall_means: [54.8 54.8 54.8 54.8]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
