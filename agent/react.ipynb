{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:38:46.758183Z",
     "start_time": "2024-09-05T12:38:42.507834Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import construct_tools\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import getpass\n",
    "import os\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from utils import process_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "\n",
    "system_prompt = (\"Answer the following question. \"\n",
    "                 \"Remember your FINAL ANSWER should be clear and concise.(a single number or phrases, not a sentence!)\"\n",
    "                 \"Follow the format: \\n\"\n",
    "                 \"FINAL ANSWER: <your answer>\")\n",
    "\n",
    "\n",
    "\n",
    "tools = construct_tools()\n",
    "tool_node = ToolNode(tools)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:38:49.387205Z",
     "start_time": "2024-09-05T12:38:49.383012Z"
    }
   },
   "source": [
    "async def react(item: dict, reactor: CompiledGraph) -> str:\n",
    "    try:\n",
    "        messages = [HumanMessage(content=item[\"context\"] + item[\"question\"])]\n",
    "        input = {\"messages\": messages}\n",
    "    except Exception:\n",
    "        raise ValueError(\"Invalid dataset_name\")\n",
    "    \n",
    "    try:\n",
    "        return await reactor.ainvoke(input=input)   \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return str(e)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gsm8k svamp tabmwp trivia_qa ambig_qa"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T12:35:46.390818Z",
     "start_time": "2024-09-05T12:35:46.196451Z"
    }
   },
   "source": [
    "dataset_name = \"tabmwp\"\n",
    "mode = \"react\"\n",
    "num_test_sample = 1000\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "batch_size = 100\n",
    "version = \"v2\"\n",
    "llm = ChatOpenAI(temperature=temperature, top_p=top_p, model=\"gpt-4o-mini\", base_url=\"https://api.chsdw.top/v1\", max_retries=3)\n",
    "graph = create_react_agent(model=llm, tools=tools, state_modifier=system_prompt)\n",
    "\n",
    "dataset = process_dataset(file_path=f\"../data/{dataset_name}.jsonl\")\n",
    "if dataset_name == \"ambig_qa\":\n",
    "    dataset = load_dataset(\"json\", data_files=f\"/Users/ariete/Projects/self-improve/output/inference/ambig_qa/cot_1000_temperature_0_top-p_1.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "print(dataset, json.dumps({key: dataset[0][key] for key in [\"context\", \"question\", \"answer\"]}, indent=4))\n",
    "results = []\n",
    "print(llm.temperature, llm.top_p)"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ChatOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m100\u001B[39m\n\u001B[1;32m      7\u001B[0m version \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mv2\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 8\u001B[0m llm \u001B[38;5;241m=\u001B[39m \u001B[43mChatOpenAI\u001B[49m(temperature\u001B[38;5;241m=\u001B[39mtemperature, top_p\u001B[38;5;241m=\u001B[39mtop_p, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-4o-mini\u001B[39m\u001B[38;5;124m\"\u001B[39m, base_url\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhttps://api.chsdw.top/v1\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_retries\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m      9\u001B[0m graph \u001B[38;5;241m=\u001B[39m create_react_agent(model\u001B[38;5;241m=\u001B[39mllm, tools\u001B[38;5;241m=\u001B[39mtools, state_modifier\u001B[38;5;241m=\u001B[39msystem_prompt)\n\u001B[1;32m     11\u001B[0m dataset \u001B[38;5;241m=\u001B[39m process_dataset(file_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../data/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.jsonl\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'ChatOpenAI' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:20<12:00, 80.03s/it]WARNING:root:Error response when hitting Wikibase: Error(code='invalid-path-parameter', message=\"Invalid path parameter: 'item_id'\", additional_properties={'context': {'parameter': 'item_id'}})\n",
      " 30%|███       | 3/10 [06:26<16:03, 137.68s/it]/Users/ariete/Projects/self-improve/agent/utils/tools.py:83: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  result[\"title\"] = BeautifulSoup(result[\"title\"], \"html.parser\").get_text()\n",
      " 50%|█████     | 5/10 [11:48<12:39, 151.95s/it]WARNING:root:Error response when hitting Wikibase: Error(code='label-not-defined', message='Item with the ID Q60997513 does not have a label in the language: en', additional_properties={})\n",
      "WARNING:langchain_experimental.utilities.python:Python REPL can execute arbitrary code. Use with caution.\n",
      "/Users/ariete/Projects/self-improve/agent/utils/tools.py:83: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  result[\"title\"] = BeautifulSoup(result[\"title\"], \"html.parser\").get_text()\n",
      "WARNING:root:Error response when hitting Wikibase: Error(code='invalid-path-parameter', message=\"Invalid path parameter: 'item_id'\", additional_properties={'context': {'parameter': 'item_id'}})\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "/Users/ariete/Projects/self-improve/agent/utils/tools.py:83: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  result[\"title\"] = BeautifulSoup(result[\"title\"], \"html.parser\").get_text()\n",
      " 60%|██████    | 6/10 [15:17<11:25, 171.26s/it]WARNING:root:Error response when hitting Wikibase: Error(code='invalid-path-parameter', message=\"Invalid path parameter: 'item_id'\", additional_properties={'context': {'parameter': 'item_id'}})\n",
      " 70%|███████   | 7/10 [18:48<09:12, 184.23s/it]/opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /opt/homebrew/Caskroom/miniconda/base/envs/selfimprove/lib/python3.12/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "100%|██████████| 10/10 [29:37<00:00, 177.72s/it]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "for i in tqdm(range(0, len(dataset), batch_size)):\n",
    "    batch = dataset.select(range(i, min(i+batch_size, len(dataset))))\n",
    "    results.extend(await asyncio.gather(*(react(item=item, reactor=graph) for item in batch)))\n",
    "    with open(f\"/Users/ariete/Projects/self-improve/output/{version}/{dataset_name}/{mode}_{len(dataset)}_temperature_{temperature}_top-p_{top_p}.jsonl\", \"w\") as f:\n",
    "        for idx, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                prediction = str(result)\n",
    "            else:\n",
    "                prediction = result[\"messages\"][-1].content\n",
    "            f.write(json.dumps({\"question\": dataset[idx][\"question\"], \"answer\": dataset[idx][\"answer\"], \"prediction\": prediction}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HotpotQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['question', 'question_id', 'question_source', 'entity_pages', 'search_results', 'answer'],\n",
      "    num_rows: 1000\n",
      "}) {'question': 'Who was the man behind The Chipmunks?', 'question_id': 'tc_2', 'question_source': 'http://www.triviacountry.com/', 'entity_pages': {'doc_source': [], 'filename': [], 'title': [], 'wiki_context': []}, 'search_results': {'description': [], 'filename': [], 'rank': [], 'title': [], 'url': [], 'search_context': []}, 'answer': {'aliases': ['David Seville'], 'normalized_aliases': ['david seville'], 'matched_wiki_entity_name': '', 'normalized_matched_wiki_entity_name': '', 'normalized_value': 'david seville', 'type': 'WikipediaEntity', 'value': 'David Seville'}}\n"
     ]
    }
   ],
   "source": [
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict, IterableDatasetDict\n",
    "from datasets.iterable_dataset import IterableDataset\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "\n",
    "\n",
    "dataset_name = \"ambig_qa\"\n",
    "mode = \"react\"\n",
    "num_test_sample = 1000\n",
    "temperature = 0\n",
    "top_p = 1\n",
    "batch_size = 100\n",
    "llm = ChatOpenAI(temperature=temperature, top_p=top_p, model=\"gpt-4o-mini\", base_url=\"https://api.chsdw.top/v1\", max_retries=3)\n",
    "graph: CompiledGraph = create_react_agent(llm, tools=tools, state_modifier=system_prompt)\n",
    "from datasets import load_dataset\n",
    "dataset: DatasetDict | Dataset | IterableDatasetDict | IterableDataset = load_dataset(\"json\", data_files=f\"../data/{dataset_name}.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "print(dataset, dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot access local variable 'input' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "result = await react(item=dataset[0], reactor=graph)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "for i in tqdm(range(0, 1000, batch_size)):\n",
    "    batch = dataset.select(range(i, min(i+batch_size, len(dataset))))\n",
    "    results.extend(await asyncio.gather(*(react(item, reactor=graph) for item in batch)))\n",
    "    with open(f\"/Users/ariete/Projects/self-improve/output/inference/{dataset_name}/{mode}_{len(dataset)}_temperature_{temperature}_top-p_{top_p}.jsonl\", \"w\") as f:\n",
    "        for idx, result in enumerate(results):\n",
    "            if isinstance(result, Exception):\n",
    "                prediction = \"None\"\n",
    "            else:\n",
    "                prediction = result[\"messages\"][-1].content\n",
    "            f.write(json.dumps({\"question\": batch[idx][\"question\"], \"answer\": batch[idx][\"answer\"], \"prediction\": prediction}) + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
