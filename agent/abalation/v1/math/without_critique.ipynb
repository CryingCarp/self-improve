{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T12:34:38.089128Z",
     "start_time": "2025-01-16T12:34:34.956650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from agent.utils.loader import load_processed_data\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"self-correct\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://api.smith.langchain.com\""
   ],
   "id": "4cd3011c37c64e00",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:23:41.744858Z",
     "start_time": "2025-01-16T13:23:40.294794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "meta_info = {\n",
    "\t\"dataset_name\": 'tabmwp1k',\n",
    "\t\"mode\": \"self-improve\",\n",
    "\t\"base_mode\": \"pot\",\n",
    "\t\"model\": \"gpt-4o-mini-2024-07-18\",\n",
    "\t\"num_samples\": -1,\n",
    "\t\"top_p\": 0.95,\n",
    "\t\"temperature\": 0,\n",
    "\t\"seed\": 42,\n",
    "\t\"batch_size\": 100\n",
    "}\n",
    "assert meta_info[\"mode\"] == \"self-improve\"\n",
    "assert meta_info[\"dataset_name\"] in [\"gsm8k\", \"math\", \"gsmhard\", \"tabmwp\", \"svamp\", \"tabmwp1k\"], \"Invalid dataset name\"\n",
    "\n",
    "processed_data_path = f\"../../../data/processed_data/{meta_info['dataset_name']}.jsonl\"\n",
    "\n",
    "dataset = load_processed_data(dataset_name=meta_info[\"dataset_name\"], file_path=processed_data_path)\n",
    "if meta_info[\"dataset_name\"] == \"tabmwp\":\n",
    "\tdataset = dataset.select_columns([\"question\", \"answer\", \"ques_type\", \"ans_type\", ])\n",
    "elif meta_info[\"dataset_name\"] in [\"tabmwp1k\", \"svamp\"]:\n",
    "\tdataset = dataset.map(lambda x: {\"question\": f\"{x['context']}\\n\\n{x['question']}\"}).remove_columns([\"context\"])\n",
    "model = ChatOpenAI(\n",
    "\tmodel_name=meta_info[\"model\"],\n",
    "\ttop_p=meta_info[\"top_p\"],\n",
    "\ttemperature=meta_info[\"temperature\"],\n",
    "\tseed=meta_info[\"seed\"],\n",
    "\topenai_api_base=\"https://api.chsdw.top/v1\"\n",
    ")\n",
    "\n",
    "if meta_info[\"num_samples\"] > 0:\n",
    "\tdataset = dataset.select(range(meta_info[\"num_samples\"]))\n",
    "print(dataset[2])"
   ],
   "id": "432fc32eecaae51f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Read the following table regarding \"Average food preparation time\" and then answer a question.\\n\\nDay | Food preparation time (minutes)\\nMonday | 25\\nTuesday | 27\\nWednesday | 18\\nThursday | 21\\nFriday | 27\\n\\nA restaurant\\'s average food preparation time was tracked from day to day as part of an efficiency improvement program. According to the table, what was the rate of change between Wednesday and Thursday?', 'answer': '3', 'ques_type': 'free_text', 'choices': None}\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:14:03.053927Z",
     "start_time": "2025-01-16T13:14:03.047054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import Sequence\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "\tquestion: str\n",
    "\tguidance: str\n",
    "\tfusion: str\n",
    "\tprediction: str"
   ],
   "id": "afa6cb0cf6d56639",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:14:06.436523Z",
     "start_time": "2025-01-16T13:14:06.429731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "guidance_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"system\",\n",
    "\t\t\t\"You are a question planner and error prone points identifier. Given a question or problem, your job is to come up with a step by step plan, and you should also identify the most error-prone points for each step, following them closely behind each step. Do not add any superfluous steps. Make sure that each step has all the information needed - do not skip steps. You should focus on the logic of how to solve the problem, rather than actually solving it.\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"user\",\n",
    "\t\t\t\"Question: {question}\"\n",
    "\t\t)\n",
    "\t])\n",
    "guidance_generator = guidance_prompt | model\n",
    "\n",
    "\n",
    "async def guidance_node(state: State) -> State:\n",
    "\tassert state[\"question\"] is not None, \"Question is required\"\n",
    "\tquestion:str = state[\"question\"]\n",
    "\tguidance:AIMessage = await guidance_generator.ainvoke(input={\"question\": question})\n",
    "\tstate[\"guidance\"] = guidance.content\n",
    "\treturn state"
   ],
   "id": "5d78152259117ee4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:14:09.567596Z",
     "start_time": "2025-01-16T13:14:09.556892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "fusion_prompt = ChatPromptTemplate.from_messages(\n",
    "\t[\n",
    "\t\t(\n",
    "\t\t\t\"system\",\n",
    "\t\t\t\"You are a fusion agent. Given a question or problem and based on the guidance, your job is to answer the question. \"\n",
    "\t\t\t\"Your response should contains two part, the first part is the fusion of the Revising Process and the second part is the final answer. In the fusion part, you should extract the information from the tool result and also indicate how you obtained the information.(which tool, which part of the result) In the final answer, \"\n",
    "\t\t\t\"do not include any explanations, context, or additional information. Just focus on delivering the exact answer as concisely as possible!!! \"\n",
    "\t\t\t\"There is no need to answer the question in the form of a complete sentence, just provide the answer in the form of a noun, time, entity, single number, yes or no, etc.\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"placeholder\",\n",
    "\t\t\t\"{messages}\"\n",
    "\t\t),\n",
    "\t\t(\n",
    "\t\t\t\"user\",\n",
    "\t\t\t\"Now based on the previous information, please fuse the tool results and revise your answer. Use the XML tag <fusion></fusion> to indicate the fusion part and <answer></answer> to indicate the final answer part.\"\n",
    "\t\t)\n",
    "\t])\n",
    "fusion_generator = fusion_prompt | model\n",
    "\n",
    "async def fusion_node(state: State) -> State:\n",
    "\tassert state[\"question\"] is not None, \"Question is required\"\n",
    "\tassert state[\"guidance\"] is not None, \"Guidance is required\"\n",
    "\tguidance_messages:Sequence[BaseMessage] = [HumanMessage(content=state[\"question\"]), AIMessage(content=state[\"guidance\"])]\n",
    "\tresponse:AIMessage = await fusion_generator.ainvoke(input={\"messages\": guidance_messages})\n",
    "\tfusion_matches = re.findall(r\"<fusion>(.*?)</fusion>\", response.content, re.DOTALL)\n",
    "\tanswer_matches = re.findall(r\"<answer>(.*?)</answer>\", response.content, re.DOTALL)\n",
    "\tif fusion_matches:\n",
    "\t\tstate[\"fusion\"] = fusion_matches[0]\n",
    "\telse:\n",
    "\t\tstate[\"fusion\"] = response.content\n",
    "\tif answer_matches:\n",
    "\t\tstate[\"prediction\"] = answer_matches[0]\n",
    "\telse:\n",
    "\t\tstate[\"prediction\"] = \"None\"\n",
    "\n",
    "\treturn state\n",
    "\n"
   ],
   "id": "5d54e73d89094e4c",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:14:16.021144Z",
     "start_time": "2025-01-16T13:14:15.060014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"guide\", guidance_node)\n",
    "workflow.add_node(\"fuse\", fusion_node)\n",
    "\n",
    "workflow.set_entry_point(\"guide\")\n",
    "workflow.add_edge(\"guide\", \"fuse\")\n",
    "workflow.add_edge(\"fuse\", \"__end__\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ],
   "id": "721cfdac0693b3df",
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:14:24.730832Z",
     "start_time": "2025-01-16T13:14:19.886898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs = {**dataset[3], \"messages\": []}\n",
    "async for event in app.astream(inputs):\n",
    "    for k, v in event.items():\n",
    "        if k != \"__end__\":\n",
    "            print(v)"
   ],
   "id": "13034f16687e9bd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?', 'guidance': 'Step 1: Determine the total distance James runs in one sprint.  \\n- **Error-prone point**: Ensure that the distance per sprint is correctly noted as 60 meters.\\n\\nStep 2: Calculate the total distance James runs in one session of 3 sprints.  \\n- Formula: Total distance in one session = Number of sprints x Distance per sprint  \\n- **Error-prone point**: Ensure the multiplication is done correctly (3 sprints * 60 meters).\\n\\nStep 3: Calculate the total number of sessions James runs in a week.  \\n- He runs 3 times a week.  \\n- **Error-prone point**: Verify that the number of sessions is correctly interpreted as 3.\\n\\nStep 4: Calculate the total distance James runs in a week.  \\n- Formula: Total distance in a week = Total distance in one session x Number of sessions per week  \\n- **Error-prone point**: Ensure that you correctly multiply the total distance from step 2 by the number of sessions from step 3. \\n\\nBy following these steps, you can determine how many total meters James runs in a week, being careful to avoid the identified error-prone points.'}\n",
      "{'question': 'James decides to run 3 sprints 3 times a week.  He runs 60 meters each sprint.  How many total meters does he run a week?', 'guidance': 'Step 1: Determine the total distance James runs in one sprint.  \\n- **Error-prone point**: Ensure that the distance per sprint is correctly noted as 60 meters.\\n\\nStep 2: Calculate the total distance James runs in one session of 3 sprints.  \\n- Formula: Total distance in one session = Number of sprints x Distance per sprint  \\n- **Error-prone point**: Ensure the multiplication is done correctly (3 sprints * 60 meters).\\n\\nStep 3: Calculate the total number of sessions James runs in a week.  \\n- He runs 3 times a week.  \\n- **Error-prone point**: Verify that the number of sessions is correctly interpreted as 3.\\n\\nStep 4: Calculate the total distance James runs in a week.  \\n- Formula: Total distance in a week = Total distance in one session x Number of sessions per week  \\n- **Error-prone point**: Ensure that you correctly multiply the total distance from step 2 by the number of sessions from step 3. \\n\\nBy following these steps, you can determine how many total meters James runs in a week, being careful to avoid the identified error-prone points.', 'fusion': 'Total distance in one sprint: 60 meters (from initial information); Total distance in one session: 3 sprints x 60 meters = 180 meters; Total distance in a week: 180 meters x 3 sessions = 540 meters.', 'prediction': '540'}\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:31:58.940106Z",
     "start_time": "2025-01-16T13:31:58.919982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm.asyncio import tqdm_asyncio\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import nest_asyncio\n",
    "\n",
    "# 配置logger\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,  # 设置日志级别\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # 设置日志格式\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"inference.log\"),  # 将日志输出到文件\n",
    "        logging.StreamHandler()  # 也输出到控制台\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(\"InferenceLogger\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "results = []\n",
    "batch_size = 100\n",
    "save_results_path = f\"../../../output/ablation/{meta_info['model']}/{meta_info['dataset_name']}/{meta_info['mode']}/without_critique_{meta_info['base_mode']}_num_samples_{meta_info['num_samples']}_top_p_{meta_info['top_p']}_temperature_{meta_info['temperature']}_seed_{meta_info['seed']}.jsonl\"\n",
    "\n",
    "async def process(item):\n",
    "    try:\n",
    "        state = await app.ainvoke({**item})\n",
    "        logger.info(f\"Processed item: {item}\")\n",
    "        return {**item, **state}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing item: {item}. Error: {e}\")\n",
    "        return {**item, \"prediction\": \"None\"}\n",
    "\n",
    "async def self_improve_inference() -> None:\n",
    "    error_indices = []  # 用于记录包含 \"ERROR\" 的条目索引\n",
    "\n",
    "    # 读取已有结果或初始化文件\n",
    "    if os.path.exists(save_results_path):\n",
    "        logger.info(f\"Loading existing results from {save_results_path}\")\n",
    "        with open(save_results_path, 'r') as file:\n",
    "            for idx, line in enumerate(file):\n",
    "                result = json.loads(line)\n",
    "                results.append(result)\n",
    "                # 检查是否存在 \"prediction: ERROR\"\n",
    "                if \"None\" == result.get(\"prediction\"):\n",
    "                    error_indices.append(idx)\n",
    "    else:\n",
    "        folder_path = os.path.dirname(save_results_path)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "        logger.info(f\"Created directory for results: {folder_path}\")\n",
    "\n",
    "    # 重新推理错误的数据\n",
    "    if error_indices:\n",
    "        logger.warning(f\"Found {len(error_indices)} ERROR entries. Retrying inference...\")\n",
    "        error_data = [dataset[idx] for idx in error_indices]\n",
    "        new_results = await tqdm_asyncio.gather(*(process(item) for item in error_data))\n",
    "        # 更新原始结果\n",
    "        for i, new_result in zip(error_indices, new_results):\n",
    "            results[i] = new_result\n",
    "\n",
    "\n",
    "    for idx in range(len(results), dataset.num_rows, batch_size):\n",
    "        batch = dataset.select(range(idx, min(idx + batch_size, dataset.num_rows)))\n",
    "        batch_results = await tqdm_asyncio.gather(*(process(item) for item in batch))\n",
    "        results.extend(batch_results)\n",
    "\n",
    "        logger.info(f\"Processed batch starting at index {idx}\")\n",
    "\n",
    "        # 保存结果\n",
    "        with open(save_results_path, 'qa') as file:\n",
    "            for result in results:\n",
    "                file.write(json.dumps(result) + \"\\n\")\n",
    "        logger.info(f\"Saved results to {save_results_path}\")"
   ],
   "id": "ea507dced72aea26",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T13:35:41.945068Z",
     "start_time": "2025-01-16T13:32:07.416560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "await self_improve_inference()\n",
    "# 保存结果"
   ],
   "id": "2b80ff65791953cb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:07<00:00,  1.48it/s]\n",
      "100%|██████████| 100/100 [00:21<00:00,  4.75it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.83it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.63it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.65it/s]\n",
      "100%|██████████| 100/100 [00:14<00:00,  6.78it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.45it/s]\n",
      "100%|██████████| 100/100 [00:17<00:00,  5.57it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.69it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.36it/s]\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open(save_results_path, 'qa') as file:\n",
    "\tfor result in results:\n",
    "\t\tfile.write(json.dumps(result) + \"\\n\")\n",
    "logger.info(f\"Saved results to {save_results_path}\")"
   ],
   "id": "51f0174406d9b735"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
