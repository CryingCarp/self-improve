{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Self Improvement\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import construct_tools, get_tools_descriptions\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = construct_tools()\n",
    "tools_descriptions = get_tools_descriptions(tools)\n",
    "tool_node = ToolNode(tools)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", base_url=\"https://api.chsdw.top/v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "MAX_ITERATIONS = 4\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    critique: Annotated[list[str], add]\n",
    "    react_messages: Annotated[list, add]\n",
    "    final_answer: Annotated[list[str], add]\n",
    "    iteration: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Reacter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage,HumanMessage\n",
    "\n",
    "react_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Identify all the candidate tools you may need to use and the corresponding tool input text based on the user's current step. \"\n",
    "     \"Always remmeber that there may be multiple tools that can be used to complete a step! So if there are more than one tool that can be used, \"\n",
    "     \"your response should contain multiple tools and their inputs. Make sure that the current step is completed before moving to the next step. \")\n",
    "    #  \"You have access to the following tools:\\n\\n\"\n",
    "    #  \"{tools_descriptions}\\n\\n\")\n",
    "     ])\n",
    "\n",
    "react_prompt = react_prompt.format(tools_descriptions=tools_descriptions)\n",
    "\n",
    "reacter = create_react_agent(model=llm, tools=tools, state_modifier=SystemMessage(content=react_prompt))\n",
    "\n",
    "def react(state):\n",
    "    if state[\"critique\"]:\n",
    "        critique = state[\"critique\"][-1]\n",
    "        inputs = {\"messages\": [(\"user\", f\"{critique}\\n Based on the previous critique, answer the question. \"),(\"user\", state[\"input\"])]}\n",
    "        result = reacter.invoke(input=inputs)\n",
    "    else:\n",
    "        inputs = {\"messages\": [(\"user\", state[\"input\"])]}\n",
    "        result = reacter.invoke(input=inputs)\n",
    "    return {\n",
    "        \"react_messages\": [result[\"messages\"]]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "critic_prompt = (\"Inspect the previous messages and identify any potential issues or errors. \"\n",
    "                 \"Is the selection of tools calling reasnonable? \"\n",
    "                 \"Check the input to the tools step by step. \"\n",
    "                 \"Is the final answer truthful?\"\n",
    "                 \"And give a better solution or input to the tools. \\n\"\n",
    "                 \"Your response should be no more than 250 words. \")\n",
    "\n",
    "final_answer_prompt = (\"Based on the conversation, provide the final answer to the user's question. \"\n",
    "                       \"The final answer should be a single number. Follow the format: \\n\"\n",
    "                       \"FINAL ANSWER: <answer> \\n\")\n",
    "\n",
    "def criticize(state):\n",
    "    if state[\"react_messages\"]:\n",
    "        react_messages = state[\"react_messages\"][-1]\n",
    "        critique = llm.invoke(react_messages + [HumanMessage(content=critic_prompt)])\n",
    "        final_answer = llm.invoke(react_messages + [HumanMessage(content=final_answer_prompt)])\n",
    "        return {\n",
    "            \"critique\": [critique.content],\n",
    "            \"final_answer\": [final_answer.content.split(\"FINAL ANSWER:\")[-1].strip()],\n",
    "            \"iteration\": 1 if not state[\"iteration\"] else state[\"iteration\"] + 1 \n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"critique\": [\"None\"],\n",
    "            \"final_answer\": [\"None\"],\n",
    "            \"iteration\": 1 if not state[\"iteration\"] else state[\"iteration\"] + 1 \n",
    "        }\n",
    "    \n",
    "# Either agent can decide to end\n",
    "from typing import Literal\n",
    "\n",
    "def should_end(state) -> Literal[\"react\", \"__end__\"]:\n",
    "    if state[\"iteration\"] >= MAX_ITERATIONS or len(state[\"final_answer\"]) > 1 and state[\"final_answer\"][-1] == state[\"final_answer\"][-2]:\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"react\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"react\", react)\n",
    "builder.add_node(\"critic\", criticize)\n",
    "\n",
    "builder.add_edge(START, \"react\")\n",
    "builder.add_edge(\"react\", \"critic\")\n",
    "\n",
    "builder.add_conditional_edges(\"critic\", should_end)\n",
    "\n",
    "graph = builder.compile()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
