{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"Please provide your {var}\")\n",
    "\n",
    "_set_if_undefined(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# Optional, add tracing in LangSmith\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"critic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tools import construct_tools, get_tools_descriptions\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "tools = construct_tools()\n",
    "tools_descriptions = get_tools_descriptions(tools)\n",
    "tool_node = ToolNode(tools)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\", base_url=\"https://api.chsdw.top/v1\", top_p=1, max_retries=3)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from operator import add\n",
    "\n",
    "MAX_ITERATIONS = 4\n",
    "\n",
    "class State(TypedDict):\n",
    "    input: str\n",
    "    react_messages: Annotated[list[list], add]\n",
    "    predictions: Annotated[list[str], add]\n",
    "    critiques: Annotated[list[str], add]\n",
    "    iteration: int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage, AIMessage\n",
    "\n",
    "critic_prompt = HumanMessage(content=(\"What's the problem of the previous answer? \"\n",
    "                                      \"Reflect on the process of problem-solving. \"\n",
    "                                      \"Identify any potential issues or errors. \"\n",
    "                                      \"Then list them in a single response. \"))\n",
    "\n",
    "async def criticize(state):\n",
    "    try:\n",
    "        messages = [critic_prompt]\n",
    "        critique = await llm.ainvoke(state[\"react_messages\"][-1] + messages)\n",
    "        messages.append(AIMessage(**critique.dict(exclude={\"type\", \"name\"})))\n",
    "    except:\n",
    "        return {\n",
    "        \"iteration\":state[\"iteration\"] + 1 ,\n",
    "        \"critiques\": [\"I'm sorry, I couldn't generate a critique. Please try again.\"]\n",
    "        } \n",
    "    return {\n",
    "    \"iteration\": state[\"iteration\"] + 1 ,\n",
    "    \"critiques\": [critique.content]\n",
    "    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Reacter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "# revise_prompt = (\"Based on the previous criqique, you should use tools to confirm each point listed one by one. \"\n",
    "#                  \"If you find any errors in the previous points, correct them and change the information in the subsequent points accordingly! \"\n",
    "#                  \"Remember that there may be multiple tools that can be used at one time. \"\n",
    "#                  \"So if there are more than one tool that can be used, your single response should contain all of them. \"\n",
    "#                  \"Then revise your answer. Remember your FINAL ANSWER should be clear and concise.(a single number or phrases, not a sentence!) \"\n",
    "#                  \"Your final response should follow the original format. For following example:\\n\\n\"\n",
    "#                  \"{question}\\n\"\n",
    "#                  \"Let's think step by step. (the reasoning of your thought)\\n\"\n",
    "#                  \"So the FINAL ANSWER is: <FINAL ANSWER>\\n\")\n",
    "\n",
    "reflect_prompt = (\"Based on the criqique, use tools to check the Truthfulness and Plausibility of your answer. \"\n",
    "                  \"If you find any errors in the previous process, correct them and change the information in the subsequent step accordingly! \")\n",
    "\n",
    "revise_prompt = (\"Based on the previous messages, revise your answer.\\n\"\n",
    "                 \"Remember your FINAL ANSWER should be clear and concise.(a single number or phrases, not a sentence!) \"\n",
    "                 \"Your response should follow the original format. For following example:\\n\\n\"\n",
    "                 \"Question: <ORIGINAL QUESTION>\\n\"\n",
    "                 \"Let's think step by step. (the reasoning of your thought)\\n\"\n",
    "                 \"FINAL ANSWER: <FINAL ANSWER>\\n\\nBegin !\\n\\n\\n\"\n",
    "                 \"Question: {question}\\n\")\n",
    "\n",
    "reacter = create_react_agent(model=llm, tools=tools, state_modifier=revise_prompt)\n",
    "\n",
    "async def react(state):\n",
    "    messages = [HumanMessage(content=f\"{state[\"input\"]}\\n{state[\"predictions\"][-1]}\\n\\n{state[\"critiques\"][-1]}\")]\n",
    "    try:\n",
    "        reflect_result = await reacter.ainvoke(input={\"messages\": messages}, config={\"recursion_limit\": 15})\n",
    "        revised_answer = await llm.ainvoke(reflect_result[\"messages\"]+[HumanMessage(content=revise_prompt.format(question=state[\"input\"]))])\n",
    "    except Exception as e:\n",
    "        return{\n",
    "            \"react_messages\": [state[\"react_messages\"][-1]], \n",
    "            \"predictions\": [\"None\"]\n",
    "        }\n",
    "    return {\n",
    "        \"react_messages\": [[HumanMessage(content=f\"{state[\"input\"]}\\n{revised_answer.content}\")]],\n",
    "        \"predictions\": [revised_answer.content],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either agent can decide to end\n",
    "from typing import Literal\n",
    "\n",
    "def should_end(state) -> Literal[\"critic\", \"__end__\"]:\n",
    "    if state[\"iteration\"] == MAX_ITERATIONS or len(state[\"predictions\"]) > 2 and state[\"predictions\"][-1].split(\"FINAL ANSWER:\")[-1].strip() == state[\"predictions\"][-2].split(\"FINAL ANSWER:\")[-1].strip():\n",
    "        return \"__end__\"\n",
    "    else:\n",
    "        return \"critic\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"critic\", criticize)\n",
    "builder.add_node(\"react\", react)\n",
    "# builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "builder.add_edge(START, \"critic\")\n",
    "builder.add_edge(\"critic\", \"react\")\n",
    "\n",
    "\n",
    "builder.add_conditional_edges(\"react\", should_end)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "batch_size = 50\n",
    "results = []\n",
    "semaphore = asyncio.Semaphore(20)\n",
    "async def process(item, dataset_name:str=\"hotpot_qa\", timeout: int = 180):\n",
    "    if dataset_name == \"hotpot_qa\":\n",
    "        messages = [HumanMessage(content=f\"{item['question']}\\n{item['prediction']}\")]\n",
    "        input = {\"react_messages\": [messages], \"input\": item[\"question\"], \"predictions\": [item[\"prediction\"]], \"iteration\": 0}\n",
    "    elif dataset_name == \"gsm8k\":\n",
    "        messages = [HumanMessage(content=f\"Use python code to solve the following problem, variable <answer> should contain the final answer. Use \\\"print(answer)\\\" to get the final answer.\\n{item['question']}\\n{item['python_code']}\")]\n",
    "        input = {\"react_messages\": [messages], \"input\": f\"Use python code to solve the following problem, variable <answer> should contain the final answer. Use \\\"print(answer)\\\" to get the final answer.\\n{item[\"question\"]}\", \"predictions\": [item[\"prediction\"]], \"iteration\": 0}\n",
    "    try:\n",
    "        async with semaphore:\n",
    "            return await asyncio.wait_for(graph.ainvoke(input=input), timeout=timeout)\n",
    "    except asyncio.TimeoutError:\n",
    "        print(f\"Timeout processing item {item}\")\n",
    "        return f\"Timeout on {item}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing item {item}: {e}\")\n",
    "        return f\"Error on {item}: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cb6628d448498b9e10fe9c44347d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['idx', 'question', 'answer', 'python code', 'prediction'],\n",
      "    num_rows: 200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset_name = \"gsm8k\"\n",
    "num_test_sample = 200\n",
    "mode = \"critic\"\n",
    "batch_size = 50\n",
    "\n",
    "dataset = load_dataset(\"json\", data_files=f\"/Users/ariete/Projects/self-improve/output/v1/gsm8k/200_pot.jsonl\", split=\"train\")\n",
    "if num_test_sample > 0:\n",
    "    dataset = dataset.select(range(num_test_sample))\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AsyncCallbackManager.merge(): Parent run IDs do not match. Using the parent run ID of the first callback manager.\n",
      "AsyncCallbackManager.merge(): Parent run IDs do not match. Using the parent run ID of the first callback manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\n",
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "70000.0\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\n",
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "70000.0\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\n",
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\n",
      "70000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = await process(dataset[2], dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\\nJosh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?', 'react_messages': [[HumanMessage(content='Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\\nJosh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\\n70000.0\\n')], [HumanMessage(content='Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\\nJosh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\\n70000.0\\n')], [HumanMessage(content='Write a python code which could be used to solve the following problem, variable <answer> should contain the final answer. Use \"print(answer)\" to get the final answer.\\nJosh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make?\\n70000.0\\n')]], 'predictions': ['70000.0\\n', 'None', 'None'], 'critiques': ['The previous answer incorrectly states that Josh made a profit of $70,000. Here are the issues and errors identified in the problem-solving process:\\n\\n1. **Incorrect Profit Calculation**: The calculation for the selling price of the house after the renovations was not correctly performed. The final selling price should account for the 150% increase on the original purchase price plus repairs, not simply a subtraction of costs.\\n\\n2. **Value Increase Misinterpretation**: The problem states the house increased in value by 150%, which should be calculated based on the cost of the house after repairs, not just the original price.\\n\\n3. **Profit Definition Understanding**: Profit is defined as the selling price minus the total expenses (purchase price + renovation costs). In the previous answer, this calculation was not performed correctly.\\n\\nTo correct the answer, the total investment should be calculated, then the selling price derived from the increase in value, and finally, the profit should be computed by subtracting the total investment from the selling price.', \"The previous answer contains the final result of $70,000. However, there are several issues or errors in the problem-solving process:\\n\\n1. **Incorrect Calculation of House Value Increase**: The problem states that the house's value increased by 150%. This means the new value should be calculated based on the initial purchase price of $80,000, not just the repair costs.\\n\\n2. **Profit Calculation Methodology**: The profit should be calculated as the difference between the selling price (the new value after renovations) and the total cost (purchase price + repairs). The calculation needs to reflect this.\\n\\n3. **Clarity on Costs**: The total investment should be clearly explained as the sum of the purchase price and the costs of repairs.\\n\\nOverall, the process should involve clearly defining the initial costs, calculating the new house value based on the percentage increase, and finally subtracting the total costs to find the profit.\\n\\nWith these issues in mind, here’s the corrected code to solve the problem accurately:\\n\\n```python\\n# Given values\\npurchase_price = 80000  # The price Josh bought the house for\\nrepair_costs = 50000    # The amount spent on repairs\\nincrease_percentage = 150 / 100  # 150% increase\\n\\n# Calculate the total investment\\ntotal_investment = purchase_price + repair_costs\\n\\n# Calculate the new value of the house after repairs\\nnew_value = purchase_price * (1 + increase_percentage)\\n\\n# Calculate profit\\nprofit = new_value - total_investment\\n\\n# Store the final answer\\nanswer = profit\\n\\nprint(answer)\\n```\\n\\nThis code accurately calculates the profit by considering the total investment and the new value of the house based on the percentage increase.\"], 'iteration': 2}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 200, batch_size):\n",
    "    batch = dataset.select(range(i, i + batch_size))\n",
    "    batch_results = await asyncio.gather(*(process(item, dataset_name) for item in batch))\n",
    "    results.extend(batch_results)\n",
    "    with open(\"/Users/ariete/Projects/self-improve/output/hotpot_qa/200_critic.jsonl\", 'w') as f:\n",
    "        for idx, item in enumerate(results):\n",
    "            if isinstance(item, str):\n",
    "                temp = {\"idx\": idx, \"question\":  dataset[idx][\"question\"], \"predictions\": [dataset[idx][\"prediction\"]], \"answer\": dataset[idx][\"answer\"]}\n",
    "                f.write(json.dumps(temp) + \"\\n\")\n",
    "            else:\n",
    "                temp = {\"idx\": idx, \"question\": item[\"input\"], \"predictions\": item[\"predictions\"], \"answer\": dataset[idx][\"answer\"]}\n",
    "                f.write(json.dumps(temp) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selfimprove",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
